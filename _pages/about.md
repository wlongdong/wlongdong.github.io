---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am currently pursuing my M.S. at SUSTech's [RCVLab](https://rcvlab.eee.sustech.edu.cn/), under the guidance of Prof. [Hong Zhang](https://faculty.sustech.edu.cn/?tagid=zhangh33&iscss=1&snapid=1&orderby=date&go=2&lang=en). Prior to this, I earned my Bachelor's degree in Electronic Information Science and Technology from Dalian Maritime University.

My research interests involve **robotic manipulation and grasping**, **mobile manipulation**, **human-robot interaction**, and **semantic reasoning for robots**. The ultimate goal is to develop autonomous agents that can perceive, reason, and interact with the physical world with the same level of Intelligence as humans.

üéíEducation
======
* M.S. Electronic Science and Technology, Southern University of Science and Technology(China), 2023 - Present
  * Department of Electrical and Electronic Engineering, School of Engineering 

* B.S. Electronic Information Science and Technology, Dalian Maritime University(China), 2019 - 2023
  * School of Information Science and Technology

üìùPublication Brief View
======
<html>

<style>
  .custom-link {
    background-color: #e0e0e0; /* Light grey background */
    border-radius: 20px; /* Rounded corners */
    padding: 2px 5px; /* Padding around the text */
    color: #000; /* Text color */
    text-decoration: none; /* Remove underline */
    font-family: Arial, sans-serif; /* Font style */
    font-size: 14px; /* Font size */
    margin-right: 6px; /* Space between buttons */
  }

  .custom-link.arxiv {
    background-color: #ffdde8; /* Color for arxiv */
  }

  .custom-link.web {
    background-color: #ffe88b; /* Color for web */
  }

  .custom-link.video {
    background-color: #d8f2ff; /* Color for web */
  }

  .custom-link:hover {
    opacity: 0.8; /* Slightly fade on hover */
  }

  papertitle {
    font-size: 18px; /* Increased font size */
    color: #224b8d;
    font-weight: inherit; /* Optional: make it bold */
    font-family: Arial, sans-serif; /* Apply a font family */
  }
.page {
  padding-right: 8% !important; /* Âº∫Âà∂‰ºòÂÖàÂ∫îÁî®Ê≠§Ê†∑Âºè */
}

</style>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
    <td style="padding:10px;width:40%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <img src="../images/RTAGrasp.png" alt="hpp" style="border-style: none">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <papertitle>RTAGrasp: Learning Task-Oriented Grasping from Human Videos via Retrieval, Transfer, and Alignment</papertitle>
      <br>
      <strong>Wenlong Dong</strong>Ôºå Dehao HuangÔºå Jiangshan LiuÔºåChao TangÔºåHong Zhang
      <br>
      <em>Accepted for publication in the 2025 IEEE/RSJ International Conference on Robotics and Automation (ICRA)</em><br>
      <a href="https://arxiv.org/pdf/2409.16033" target="_blank" class="custom-link arxiv">arxiv</a>
      <a href="https://sites.google.com/view/rtagrasp/home"  target="_blank" class="custom-link web">site</a>
      <a href="https://youtu.be/kjbltBw84Rg" target="_blank" class="custom-link video">video</a>
    </td>
  </tr>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
    <td style="padding:10px;width:40%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <img src="../images/HGDiffuser.png" alt="hpp" style="border-style: none">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <papertitle>HGDiffuser: Efficient Task-Oriented Grasp Generation via Human-Guided Grasp Diffusion Models</papertitle>
      <br>
      Dehao Huang, <strong>Wenlong Dong</strong>, Chao Tang, Hong Zhang
      <br>
      <em>Submitted to the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em><br>
      <a href="https://arxiv.org/pdf/2503.00508" target="_blank" class="custom-link arxiv">arxiv</a>
      <a href="https://sites.google.com/view/hgdiffuser"  target="_blank" class="custom-link web">site</a>
      <a href="https://youtu.be/fUt6cE9SZoY" target="_blank" class="custom-link video">video</a>
    </td>
  </tr>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
    <td style="padding:10px;width:40%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <img src="../images/handover.png" alt="hpp" style="border-style: none">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <papertitle>Leveraging Semantic and Geometric Information for Zero-Shot Robot-to-Human Handover</papertitle>
      <br>
      Jiangshan Liu, <strong>Wenlong Dong</strong>, Jiankun Wang, Max Q-H Meng
      <br>
      <em>Accepted for publication in the 2025 IEEE/RSJ International Conference on Robotics and Automation (ICRA)</em><br>
      <a href="https://arxiv.org/pdf/2409.17621" target="_blank" class="custom-link arxiv">arxiv</a>
      <a href="https://sites.google.com/view/vlm-handover/"  target="_blank" class="custom-link web">site</a>
      <a href="https://youtu.be/_Q36TWdC59Q" target="_blank" class="custom-link video">video</a>
    </td>
  </tr>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
    <td style="padding:10px;width:40%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <img src="../images/FUNCTO.png" alt="hpp" style="border-style: none">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <papertitle>FoundationGrasp: Generalizable Task-Oriented Grasping with Foundation Models</papertitle>
      <br>
      Chao Tang, Dehao Huang, <strong>Wenlong Dong</strong>, Ruinian Xu, Hong Zhang
      <br>
      <em>Published in 2025 IEEE Transactions on Automation Science and Engineering (T-ASE)</em><br>
      <a href="https://arxiv.org/abs/2404.10399" target="_blank" class="custom-link arxiv">arxiv</a>
      <a href="https://sites.google.com/view/foundationgrasp"  target="_blank" class="custom-link web">site</a>
      <a href="https://youtu.be/B6iTa6BRB1w" target="_blank" class="custom-link video">video</a>
    </td>
  </tr>
</table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
    <td style="padding:10px;width:40%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <img src="../images/graspGPT.gif" alt="hpp" style="border-style: none">
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
      <papertitle>FUNCTO: Function-Centric One-Shot Imitation Learning for Tool Manipulation</papertitle>
      <br>
      Chao Tang, Anxing Xiao, Yuhong Deng, Tianrun Hu, <strong>Wenlong Dong</strong>, Hanbo Zhang, David Hsu, and Hong Zhang
      <br>
      <em>Arxiv, 2025</em><br>
      <a href="https://arxiv.org/pdf/2502.11744" target="_blank" class="custom-link arxiv">arxiv</a>
      <a href="https://sites.google.com/view/functo"  target="_blank" class="custom-link web">site</a>
      <a href="https://youtu.be/E_NXAZKRvWk" target="_blank" class="custom-link video">video</a>
    </td>
  </tr>
</table>



</html>

üçªSelected Honors
======
* **Outstanding Graduate Award of Liaoning Province**, 2023
* **Top 10 University Student Nominee**, 2023
* **Holder of a National Invention Patent**
* **Approved for a National Undergraduate Innovation and Entrepreneurship Project**
* **National First Prize**, Robot Developer Competition **ROBOCOM** 2022
* **National First PrizeÔºåThe Only Champion in Individual Event**, National College Embedded Chip and System Design Competition, 2022
* **National Second Prize**, National Software and Information Technology Professional Competition, 2021
* **National Third Prize**, China Collegiate Computing Competition, 2022
* **Provincial First Prize**, "National College Students Mathematical Contest in Modeling, Liaoning Provincial Division, 2021
* **Gold Award**, "Challenge Cup" China College Students‚Äô Entrepreneurship Competition, Liaoning Provincial Division, 2022
